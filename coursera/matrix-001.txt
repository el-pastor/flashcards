	The Function
Set	an unordered collection of objects
A ⊆ B	"A is a subset of B"
x ∈ ℝ, x ∈ R	"x is a member of the set of real numbers"
{ x ∈ ℝ : x > 0 }, { x ∈ R : x > 0 }	"The set consisting of all elements x of the set of real numbers such that x is greater than 0"
Cardinality	The term for the number of elements in a set
|S|	The cardinality of the set S
Cartesian product	The term for the set of all pairs (a,b) where a ∈ A and b ∈ B
A x B, A × B	"The cartesian product of A and B"
|A x B|	|A| x |B|, if A and B are finite sets
image	The output of a single input under a given function
image	The outputs of a set of inputs under a given function
f(q) = r	"q maps to r under f"
domain	A given set of inputs
co-domain	The set from which an image can be chosen
f : D → F, f : D -> F	"f is a function with domain D and co-domain F"
Identity function	f: D → D
maps to (elements)	The meaning of ↦
maps to (sets)	The meaning of → 
composed with	The meaning of ∘
subset, is a subset of	The meaning of ⊆
proper subset, is a proper subset of	The meaning of ⊂
element, is an element of	The meaning of ∈
real numbers, the set of real numbers	The meaning of ℝ
the set of such that	The meaning of { : }
g(f(x))	Given f:A→B and g:B→C, then (g∘f):A→C is defined by 
functional composition	The term for the relation: (g∘f):A→C then g(f(x))
associativity	h ∘ (g ∘ f) = (h ∘ g) ∘ f
functional inverses	if f ∘ g and g ∘ f are defined and are identity functions then f and g are
invertible	A function that has an inverse is 
onto	f:D→F, if for every z∈F there exists an a∈D such that f(a) = z, then f is 
one-to-one	f:D→F, if for every f(x) = f(y) implies that x = y, then f is 
Function invertability theorem	A function f is invertible if and only if it is one-to-one and onto
	The Field
i	x, if x² = -1
complex	a number with a real part and an imaginary part
the set of complex numbers	the meaning of ℂ
absolute value	distance from the origin to a point in the complex plane
|z|	absolute value of a point z in the complex plane
translation	f(z) = z + z₀ in the complex plane implies a
scaling	f(z) = az₀ in the complex plane implies a
reflection	f(z) = -z₀ in the complex plane implies a
rotation	f(z) = iz₀ in the complex plane implies a
Euler's formula	For any real number θ, e^θi is the point z on the unit circle with argument θ
Galois field	The meaning of GF
GF(2)	The Galois field with two elements: 0 and 1
exlusive-or	Addition under GF(2) is equivalent to the logical operation
and	multiplication under GF(2) is equivalent to the logical operation 
	The Vector
scalar	A field element of a vector
sparse	A vector consisting mostly of zero values is 
zero vector	
Associative	Law that under vector addition, (x + y) + z = x + (y + z)
Commutatitive	Law that under vector addition, x + y = y + x
Associative	Law that under scalar-vector multiplication, α(βv) = (αβ)v
Ditributive	Law that under scalar-vector multiplication and vector addition, α(u + v) = αu + αv
origin and v	The set of points {αv:α∈R, 0≤α≤1} forms the line segment between the
translation	Any vector can be expressed as a line segment through the origin and a vector that expresses an operation on the points that form that line by 
convex	A vector combination αu + βv, where 0 ≤ α ≤ 1, 0 ≤ β ≤ 1, and α + β = 1 is
convex	The line segment joining two vectors, u and v, consists of the set of combinations of u and v that are 
1	Any line can be expressed as a vector combination αu + βv, where the scalars α + β = 
affine	a vector combination αu + βv, where α + β = 1 is
affine	A line through two vectors u and v can be described by the set of all combinations of u and v that are 
affine combination	a useful way of defining a line joining two vectors
negative	the difference between convex and affine combinations is that the convex scalars cannot be 
a line segment	A convex combination of two vectors can be used to describe 
an infinite line	An affine combination of two vectors can be used to describe 
	
invertible	Addition of vectors over GF(2) is
perfect secrecy	Encryption by addition of vectors over GF(2) can achieve

	Dot product
dot-product, scalar product	The sum of the product of corresponding entries in two vectors
scalar	The dot product of two vectors is a
dot-products	Similarities in different data sources expressed as vectors can be measured using
Fast fourier transform	An efficient method for measuring the dot product of two vectors
commutatitivity	The law that states that for two vectors, v and x, v · x = x · v
homogeneity	The law that states that for two vectors, v and x, (αu) · v = α(u·v)
distributive	The law that states that for two vectors, v and x, (u+v)·x = u·x + v·x
dot-product over GF(2)	
	THE VECTOR SPACE
linear	A combination of vectors each multiplied by a different scalar
span	The set of all vectors that can be produced from all possible linear combinations of a set of vectors
1	The number of vectors in Span {}
2	The number of vectors in Span{[1,1]} over GF(2)
2	The number of vectors in Span{[0,0],[1,1]} over GF(2)
4	The number of vectors in Span{[0,1],[1,1]} over GF(2)
generators	Any set of vectors that span a vector space is a set of 
[0,1], [1,0]	The standard generators for ℝ² 
0	The dimensionality of the empty set
1	The dimensionality of a single non-zero vector
2	The maximum dimensionality of two non-zero vectors
point	The convex hull of a single vector is a 
line segment	The convex hull of two vectors is a 
triangle	The convex hull of three vectors is a 
polygon	The convex hull of three or more vectors in the same plane is a 
vector space	A plane described by vectors that goes through the origin
affine space	A plane described by a vector space V and a vector 
affine combination
affine hull
homogeneous	linear equation

checksum

u+v 	Always in a vector space, if two vectors u and v are in that vector space
associative	Matrix multiplication is 
Matrix inverse	A -1
onto	If f in an invertible function then f is one-to-one and
Invertible
AA-1 is the identity matrixp

trivial vector space


Null space	Given a Matrix A, the set of vectors where A * u = 0
Homogeneous linear system	A vector is in the null space of a matrix if and only if it is a solution to the 
vector space	The null space is a 
linear system	A matrix-vector product can be expressed a set of equations, also know as a
homogenous	A linear system where the solutions to all the equations is zero is

	Error-correcting codes
nibble, nybble	A 4-bit sequence is know as a 
7 bits	In Hamming's code, a message of 4 bits is represented as a codeword of 
generator	In Hamming's code, the 7x4 matrix that is used to create a codeword is known as the 
Check matrix	In Hamming's code, the 3x7  matrix used for identifying errors in a transmitted codeword is called the
Null space	In Hamming's code, for the check matrix, the 7-vector representing the codeword is (uniquely) in its
error	In Hamming's code, if the product of the check matrix and the codeword is not [0,0,0], then the codeword has an
error syndrome	In Hamming's code, the product of the check matrix and the codeword is known as the 
codeword	In Hamming's code, if a one-bit error has been introduced into the codeword, then the position of that error is given by the column of the check matrix that matches the product of the check matrix and the
non-zero value	In Hamming's code, the original 4-bit sequence can
be retrieved from the error-corrected codeword by multiplying it by a 4x7 matrix with rows that correspond to the columns of the original generator matrix that each have precisely one

span	all multiples of a vector
affine	fancy word for linear

	Basis
Basis	A linearly independent set of generators for a vector space
Grow	The algorithm used to find the minimum number of vectors that span a vector space starting from an empty set
Shrink	The algorithm used to find the minimum number of vectors that span a vector space starting from a finite set of spanning vectors
Graph	A representation of the connexions between
Node	In a graph, a point that may be connected to other points
Edge	In a graph, a link between two nodes
Neigbours	In a graph, two nodes that are connected by an edge are both
Dominating	In a graph, a set in which all nodes are in the set or are neighbours of a node in the set
Path	In a graph, a series of connected edges
Cycle	In a graph, a path that begins and ends at the same node
Spanning	In a graph, if for a set of edges there is a path connecting each endpoint of every edge then the set is 
Forest	In a graph, a set of edges that contains no cycles
Weight	In a graph, edges that have real-number values attached to them have a  
Minimum spanning forest	In a graph, a spanning set whose edges have the minimum total weight
linearly dependent	In a graph, if a set forms a cycle then it is 
linearly independent	In a graph, if a set forms a forest then it is 


superfluous	For any set of vectors, a vector that can be written as a linear combination of the other vectors is 
non-zero	A vector that can be expressed a linear combination of some set of vectors can replace any of those vectors without affecting the span of the vectors as long as the values of their representations are 

	
trivial	A linear combination of vectors where all... 
independent	The zero vector cannot be written as a nontrivial set of vectors that are
trivial	A set of vectors is linearly dependent if the null space of the matrix representing those vectors is

Basis	Every vector space has a
1	the total number of representations of a vector in terms of the basis vectors


	Dimension
Dimension	The size of the basis of a vector space
Size	All bases for a given vector space have the same 
Rank	The maximum number of linearly independent vectors of  a matrix
Equal	The dimension of a vector space and the rank of a matrix that represents that vector space are always 
Row space	The vector space generated by the row vectors of a matrix
Column space	The vector space generated by the column vectors of a matrix
Equal	The dimension of the row space of a matrix and the dimension of its column space are

Cardinality
Kernel	For linear functions, the null space of a matrix is the same as the 
f	If f(x) = 0, then x is in the kernel of 
Ax	If f is a linear function, then we can represent it as a matrix (A) product, so that f(x) = 
trivial	If the zero vector is the only vector in the kernal, then the kernal is 
one-to-one	By the one-to-one lemma, if a kernal is trivial
linearly independent	To demonstrate that a set of vectors for a basis of a vector space, we need to show that they are 

triangular	We can use backward substitution to solve a matrix-vector equation when the matrix is 

Span	By the Simplified Exchange Lemma, if there is a set S, then for every vector z in the span of S there is a vector in S that z can replace without changing the set's
Linearly independent	By the Exchange Lemma, if there is a subset A of a larger set S, then for every vector z in the Span of S there is a vector in S - A that it can replace without changing the span of S, so long as A ∪ {z} is 
Size, Cardinality	By the Morphing Lemma, no generating set for a vector space can have a cardinality less than the cardinality of a basis for the vector space and therefore all bases for a vector space have the same
Span T	By the Subset-Basis Lemma, Every finite set T of vectors contains a subset that is a basis for
C	By the superset-Basis Lemma, any linearly independent set of vectors C in a vector space A, a basis can be formed that contains all the vectors in 
u=w	By the Dimension Lemma, if u is a subspace of w and the dimensions of u and w are equal, then 
Equal	By the Rank Theorem, for every matrix, row rank and column rank are 
dim V	By the Kernel-Image Theorem, for any linear function f : V → W, dim Ker f + dim Im f =   
dim W	By the Linear-Function Invertibility Theorem, for any linear function f : V → W, f is invertible iff dim Ker f = 0 and dim V = 
	
nullity	For a matrix A, the dimension of the null space of A, Null A, is known as its
n	By the Rank-Nullity theorem, for any n-column matrix A, nullity A + rank A =





	Gaussian elimination
Basis	Given a span of vectors, Gaussian elimination will find the
Dimension	Once the basis of a span of vectors has been found, we also know its
Matrix equation	Expressing a given vector as a linear combination of other given vectors is to solve a 
Null space	Finding a basis for the solution set of a homogeneous linear system is the same as finding its
homogenous linear system
Linearly independent	If a matrix is invertible, then all its rows are 
Pivot	 In Gaussian elimination, the name given to the row that is chosen first in order to perform a transformation on another row in the matrix
matrix	Using Gaussian elimination to solve a system of equations, step 1 is to express the equations as a 
Invertible	Using Gaussian elimination to solve a system of equations, compute matrices M and U such that M*A = U where M is 
in echelon form	Using Gaussian elimination to solve a system of equations, compute matrices M and U such that M*A = U where U is 
Back substitution	Using Gaussian elimination to solve a system of equations, the equation M*A = U can be solved (assuming U is triangular) by 
row addition operation	Using Gaussian elimination to solve a system of equations, start with M1*A = U1 where M1 represents a single 
echelon form	Using Gaussian elimination to solve a system of equations, start with M1*A = U1 where U1 is the same as matrix A but one step closer to 
Mb	Using Gaussian elimination to solve a system of equations, if M*A = U, then the x in the equation Ax = b can be found by solving Ux = 

Equal	The rank of a matrix, the dimension of its row space or its column space, the maximum number of linearly independent rows or columns, and the number of pivots in any echelon form of the matrix are all 

Re duced row echelon form

	Inner product
distance	The distance between two vectors is the length of their
Norm	The length of a vector is referred to as its
Norm	If v is a vector, ‖v‖ is its 
Inner product	If u and v are vectors, then 〈u,v 〉is their
Inner product	‖v‖ = √〈v,v 〉defines the vector v's
Dot product	For vectors over ℝ, we define the inner product of two vectors to be the same as the
Linearity	〈u + v, w 〉= 〈u, w 〉+ 〈v, w 〉implies 
Symmetry	〈u,v 〉= 〈v,u 〉implies
Homogeneity	〈αu,v 〉= α〈u,v 〉implies 
0	Two vectors u and v are orthogonal if 〈u,v 〉= 
Parallel	Given two vectors a and b, the equation σ = a.b/a.a gives that part of b in terms of a for which b and a are 


	Orthogonalization
orthogonal
orthogonal complement
orthonormal
column-orthonormal
orthogonal complement matrix
triangular matrix







	

